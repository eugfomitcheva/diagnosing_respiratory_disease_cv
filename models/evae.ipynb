{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Inspiring EVAE-Net\n",
        "https://www.mdpi.com/2075-4418/12/11/2569\n",
        "\n",
        "Implementation has been simplified and adapted slgihtly."
      ],
      "metadata": {
        "id": "kzuK4-BGV8IU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organizing Data #"
      ],
      "metadata": {
        "id": "O6psw7ckHCcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kri_iQHdHRZc",
        "outputId": "94cf2f5d-0324-4468-ebc8-8ffcd7276253"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't need to re-run -- Data creation"
      ],
      "metadata": {
        "id": "Q1PDJwKzbowB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import os\n",
        "# from shutil import copyfile\n",
        "\n",
        "# # Set paths to image folders\n",
        "# class1_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/Viral_Pneumonia/images'\n",
        "# class2_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/Normal/images'\n",
        "# class3_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/Lung_Opacity/images'\n",
        "# class4_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/COVID/images'\n",
        "\n",
        "# # Set paths to output directories\n",
        "# train_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/train'\n",
        "# val_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/val'\n",
        "# test_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/test'\n",
        "\n",
        "# # Create output directories\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# # Split images into train, validation, and test sets\n",
        "# for class_dir, class_name in zip([class1_dir, class2_dir, class3_dir, class4_dir], ['class1', 'class2', 'class3', 'class4']):\n",
        "#     image_files = os.listdir(class_dir)\n",
        "#     train_files, test_files = train_test_split(image_files, test_size=0.1, random_state=42)\n",
        "#     train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)\n",
        "\n",
        "#     # Copy train images to train folder\n",
        "#     for file_name in train_files:\n",
        "#         src_path = os.path.join(class_dir, file_name)\n",
        "#         dst_path = os.path.join(train_dir, class_name, file_name)\n",
        "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "#         copyfile(src_path, dst_path)\n",
        "\n",
        "#     # Copy validation images to validation folder\n",
        "#     for file_name in val_files:\n",
        "#         src_path = os.path.join(class_dir, file_name)\n",
        "#         dst_path = os.path.join(val_dir, class_name, file_name)\n",
        "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "#         copyfile(src_path, dst_path)\n",
        "\n",
        "#     # Copy test images to test folder\n",
        "#     for file_name in test_files:\n",
        "#         src_path = os.path.join(class_dir, file_name)\n",
        "#         dst_path = os.path.join(test_dir, class_name, file_name)\n",
        "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "#         copyfile(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "ohY784FXHCJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzyVsKjhi0v0"
      },
      "source": [
        "# Advanced Models: Modified EVAE-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IL3egfh8i0v3"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "kAJB8cBKi0v5"
      },
      "outputs": [],
      "source": [
        "class EVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes):\n",
        "        super(EVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes # 4 classes\n",
        "        \n",
        "        # Define ResNet50 Encoder\n",
        "        # resnet = models.resnet18(pretrained=True)\n",
        "        # resnet_layers = list(resnet.children())[:-1]  # Remove last layer (classification head)\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        resnet.fc = torch.nn.Linear(in_features = 512, out_features = 4)\n",
        "        resnet.load_state_dict(torch.load(\"/content/drive/MyDrive/finetuned_resnet.pth\"))\n",
        "        resnet_layers = list(resnet.children())[:-1] \n",
        "        # resnet_layers = list(resnet.children())\n",
        "\n",
        "        # loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        # optimizer = torch.optim.Adam(resnet18.parameters(), lr = 3e-5)\n",
        "\n",
        "        self.resnet_encoder = nn.Sequential(*resnet_layers)\n",
        "        \n",
        "        # Define VGG16 Encoder\n",
        "        vgg16 = models.vgg16(pretrained=True)\n",
        "        vgg16_layers = list(vgg16.features.children())[:-1]  # Remove last layer (max pooling)\n",
        "        self.vgg16_encoder = nn.Sequential(*vgg16_layers)\n",
        "\n",
        "        # Define reparameterization layers\n",
        "        self.fc0 = nn.Linear(100864, latent_dim)\n",
        "        self.fc1 = nn.Linear(latent_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, latent_dim*2)\n",
        "\n",
        "        # Define classification head\n",
        "        self.classification_head = nn.Linear(latent_dim, num_classes)\n",
        "        \n",
        "        # Define decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def decode(self, z):\n",
        "        x_hat = self.decoder(z.unsqueeze(-1).unsqueeze(-1))\n",
        "\n",
        "        return x_hat\n",
        "\n",
        "    def encode(self, x):\n",
        "        # encode\n",
        "        resnet_features = self.resnet_encoder(x)\n",
        "        vgg16_features = self.vgg16_encoder(x)\n",
        "\n",
        "        # flatten the features and concatenate them\n",
        "        features = torch.cat([resnet_features.view(x.size(0), -1), \n",
        "                              vgg16_features.view(x.size(0), -1)], dim=1)\n",
        "        \n",
        "        # apply reparameterization\n",
        "        x = F.relu(self.fc0(features))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "\n",
        "        return z, mu, log_var\n",
        "\n",
        "        # def forward(self, x):\n",
        "    #     mu, log_var = self.encode(x)\n",
        "    #     std = torch.exp(0.5 * log_var)\n",
        "    #     eps = torch.randn_like(std)\n",
        "    #     z = eps * std + mu\n",
        "    #     x_hat = self.decode(z)\n",
        "    #     y = self.classification_head(z)\n",
        "    #     return x_hat, y, mu, log_var\n",
        "\n",
        "    def forward(self, x):\n",
        "          # print('x:', x.shape)\n",
        "          z, mu, log_var = self.encode(x)\n",
        "          x_hat = self.decode(z)\n",
        "          y = self.classification_head(z)\n",
        "          # print('x_hat:', x_hat.shape)\n",
        "          # print('z:', z.shape)\n",
        "          # print('y:', y.shape)\n",
        "          return x_hat, y, mu, log_var\n",
        "    \n",
        "    def loss_function(self, x_hat, x, y, target, mu, log_var):\n",
        "        num_pixels = x.shape[1] * x.shape[2] * x.shape[3]\n",
        "\n",
        "        # Upsample to get x and x_hat pixels matching -- improvements I'm sure can be made here\n",
        "        x_hat_upsampled = F.interpolate(x_hat, size=x.shape[2:], mode='nearest') # align_corners=False\n",
        "      \n",
        "        # Compute reconstruction loss\n",
        "        recons_loss = F.mse_loss(x_hat_upsampled, x, reduction='sum')\n",
        "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "        # Lcls = F.cross_entropy(torch.argmax(y, dim=1), torch.argmax(target, dim=1))\n",
        "        Lcls = F.cross_entropy(y, target.argmax(dim=1))\n",
        "        \n",
        "        return recons_loss, kld_loss, Lcls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training EVAE"
      ],
      "metadata": {
        "id": "0wFHZC0odaAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms # need to adapt image format\n",
        "\n",
        "\n",
        "# Access train data\n",
        "train_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/train'\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "train_data = datasets.ImageFolder(train_dir, transform=transform)"
      ],
      "metadata": {
        "id": "RWtgOVgm-ovV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "siZyCYhz5v08"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# Training loop\n",
        "\n",
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, y, mu, log_var = model(data)\n",
        "        target_onehot = F.one_hot(target, num_classes=4).float() \n",
        "        mse, kld, Lcls = model.loss_function(recon_batch, data, y, target_onehot, mu, log_var)\n",
        "        loss = mse + kld + Lcls\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "OV192UynYuQX"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = EVAE(latent_dim=256, num_classes=4).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(model, optimizer, train_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "w6Sz5yncY01h",
        "outputId": "79ec7dc9-16b7-4cef-b60e-d3a9e32aaf0b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/248 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-cffd315cbd66>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-106-d5ff6d0003c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtarget_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-8852a7a32de5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m           \u001b[0;31m# print('x:', x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m           \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m           \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-8852a7a32de5>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mresnet_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mvgg16_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2048x1 and 512x4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVAE Validation"
      ],
      "metadata": {
        "id": "caWdRypaWT75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access eval data\n",
        "val_dir = '/content/drive/MyDrive/COVID-19_Radiography_Dataset/val'\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "val_data = datasets.ImageFolder(val_dir, transform=transform)"
      ],
      "metadata": {
        "id": "oTXfyEP95Y7Q"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "tkbDXFCB5n1f"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "def get_results(model, val_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    \n",
        "    y_true_int = []\n",
        "    y_pred_int = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(val_loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            _, y_hat, _, _ = model(data)\n",
        "            y_hat = torch.softmax(y_hat, dim=1)\n",
        "            y_true.extend(target.tolist())\n",
        "            y_pred.extend(y_hat.tolist())\n",
        "\n",
        "    y_true = F.one_hot(torch.tensor(y_true)).numpy()\n",
        "    y_pred = np.array(y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
        "    acc = accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "\n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "j45xRw4hGAxv"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = get_results(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JinjzVBl5QYA",
        "outputId": "a9b8e51d-3394-4799-d067-2d52004a16ca"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 275/275 [00:14<00:00, 18.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference on Test Set"
      ],
      "metadata": {
        "id": "C0w7cGOsQLKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics for Test Set"
      ],
      "metadata": {
        "id": "Gojo6fgTNYYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert format of get_results output\n",
        "y_true_int = []\n",
        "\n",
        "for ele in y_true:\n",
        "    class_label = ele.tolist().index(max(ele.tolist()))\n",
        "    y_true_int.append(class_label)"
      ],
      "metadata": {
        "id": "dl3JGi3yHkkW"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_int = []\n",
        "\n",
        "for ele in y_pred:\n",
        "    class_label = ele.tolist().index(max(ele.tolist()))\n",
        "    y_pred_int.append(class_label)"
      ],
      "metadata": {
        "id": "rC8ey82iIXxf"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to calculate multiclass AUC\n",
        "def multiclass_auc(test, pred, average=\"macro\"):\n",
        "    \n",
        "    # Create set of unique classes\n",
        "    unique = set(test)\n",
        "    auc_dict = {}\n",
        "    \n",
        "    # Loop through each class\n",
        "    for class_i in unique:\n",
        "        \n",
        "        # Create list of classes other than class_i\n",
        "        other_class = [x for x in unique if x != class_i]\n",
        "\n",
        "        # Get test / prediction values for each class\n",
        "        new_test = [0 if x in other_class else 1 for x in test]\n",
        "        new_pred = [0 if x in other_class else 1 for x in pred]\n",
        "\n",
        "        # Calculate AUC, add to dictionary\n",
        "        auc = roc_auc_score(new_test, new_pred, average = average)\n",
        "        auc_dict[class_i] = auc\n",
        "\n",
        "    return auc_dict"
      ],
      "metadata": {
        "id": "4PH2qBdYNVwL"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = multiclass_auc(y_true_int, y_pred_int, average=\"macro\")\n",
        "print('AUC by Class:', auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YateW_8vIUwF",
        "outputId": "8e411259-53b0-48ca-a221-bc87a8d4b88d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC by Class: {0: 0.90625, 1: 0.7782692975500028, 2: 0.6993939393939393, 3: 0.7220575887785844}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "overall_accuracy = accuracy_score(y_pred_int, y_true_int)\n",
        "overall_precision = precision_score(y_pred_int, y_true_int, average=\"macro\")\n",
        "\n",
        "print(\"Overall Accuracy: \", overall_accuracy)\n",
        "print(\"Overall Precision: \", overall_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VymGODJGJm2Y",
        "outputId": "fa5ab6ec-e29c-4f6e-b9fa-09ccaf234ee2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy:  0.6672727272727272\n",
            "Overall Precision:  0.6640768075598857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5AzvC1BKWVvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.2 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1da3383a1b58fe481baf23ca14731c20d0a972ba0c6221953a6c3e65df3165e3"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}