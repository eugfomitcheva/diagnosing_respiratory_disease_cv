{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Inspiring EVAE-Net\n",
        "https://www.mdpi.com/2075-4418/12/11/2569\n",
        "\n",
        "Implementation has been simplified and adapted slgihtly."
      ],
      "metadata": {
        "id": "kzuK4-BGV8IU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organizing Data #"
      ],
      "metadata": {
        "id": "O6psw7ckHCcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "path_to_utils='/content/drive/MyDrive/Colab Notebooks/healthcare_data' # CHECK PATH.\n",
        "sys.path.append(path_to_utils)\n",
        "os.chdir(path_to_utils)"
      ],
      "metadata": {
        "id": "kri_iQHdHRZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "JQno5I2c_R8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "9EapcUuW3Uhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzyVsKjhi0v0"
      },
      "source": [
        "# Advanced Models: Modified EVAE-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL3egfh8i0v3"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow_probability as tfp\n",
        "# import tensorflow as tf\n",
        "\n",
        "# def mmd_loss(source_features, target_features):\n",
        "#     rbf_kernel = tfp.math.psd_kernels.ExponentiatedQuadratic()\n",
        "#     loss = tfp.stats.maximum_mean_discrepancy(source_features, target_features, kernel=rbf_kernel)\n",
        "#     return loss"
      ],
      "metadata": {
        "id": "SpfG1-pYmWLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAJB8cBKi0v5"
      },
      "outputs": [],
      "source": [
        "class EVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes):\n",
        "        super(EVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes # 4 classes\n",
        "        self.conv_transpose = nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=14, stride=14, padding=0)\n",
        "        \n",
        "        # can use torch ResNet + VGG or FT on data\n",
        "\n",
        "        # Define ResNet50 Encoder\n",
        "        # resnet = models.resnet18(pretrained=True)\n",
        "        # resnet_layers = list(resnet.children())[:-1]  # Remove last layer (classification head)\n",
        "        resnet = models.resnet18(weights=False)\n",
        "        resnet.fc = torch.nn.Linear(in_features = 512, out_features = 4)\n",
        "        resnet.load_state_dict(torch.load(\"/content/drive/MyDrive/finetuned_resnet.pth\")) # CHECK PATH.\n",
        "        resnet_layers = list(resnet.children())[:-1]\n",
        "        self.resnet_encoder = nn.Sequential(*resnet_layers)\n",
        "        \n",
        "        # Define VGG16 Encoder\n",
        "        vgg16 = models.vgg16(weights=False)\n",
        "        # vgg16_layers = list(vgg16.features.children())[:-1]  # Remove last layer (max pooling)\n",
        "        # vgg16 = models.vgg16(pretrained=True)\n",
        "        vgg16.fc = torch.nn.Linear(in_features = 512, out_features = 4)\n",
        "        vgg16.load_state_dict(torch.load(\"/content/drive/MyDrive/finetuned_vgg.pth\")) # CHECK PATH.\n",
        "        vgg16_layers = list(vgg16.features.children())[:-1]\n",
        "        self.vgg16_encoder = nn.Sequential(*vgg16_layers)\n",
        "\n",
        "        # Define reparameterization layers\n",
        "        self.fc0 = nn.Linear(100864, latent_dim)\n",
        "        self.fc1 = nn.Linear(latent_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, latent_dim*2)\n",
        "\n",
        "        # Define classification head\n",
        "        self.classification_head = nn.Linear(latent_dim, num_classes)\n",
        "        \n",
        "        # Define decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def decode(self, z):\n",
        "        x_hat = self.decoder(z.unsqueeze(-1).unsqueeze(-1))\n",
        "        return x_hat\n",
        "\n",
        "    def encode(self, x):\n",
        "        # encode\n",
        "        resnet_features = self.resnet_encoder(x)\n",
        "        vgg16_features = self.vgg16_encoder(x)\n",
        "\n",
        "        # flatten the features and concatenate them\n",
        "        features = torch.cat([resnet_features.view(x.size(0), -1), \n",
        "                              vgg16_features.view(x.size(0), -1)], dim=1)\n",
        "        \n",
        "        # apply reparameterization\n",
        "        x = F.relu(self.fc0(features))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "\n",
        "        return z, mu, log_var\n",
        "\n",
        "    def forward(self, x):\n",
        "          z, mu, log_var = self.encode(x)\n",
        "          x_hat = self.decode(z)\n",
        "          y = self.classification_head(z)\n",
        "          return x_hat, y, mu, log_var\n",
        "    \n",
        "    def loss_function(self, x_hat, x, y, target, mu, log_var):\n",
        "        # num_pixels = x.shape[1] * x.shape[2] * x.shape[3]\n",
        "\n",
        "        # Upsample to get x and x_hat pixels matching\n",
        "        # x_hat_upsampled = F.interpolate(x_hat, size=x.shape[2:], mode='bilinear') # align_corners=False\n",
        "        x_hat_upsampled = self.conv_transpose(x_hat)\n",
        "      \n",
        "        # Compute reconstruction loss\n",
        "        recons_loss = F.mse_loss(x_hat_upsampled, x, reduction='sum')\n",
        "        # Compute kld loss\n",
        "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "        Lcls = F.cross_entropy(y, target.argmax(dim=1))\n",
        "        \n",
        "        return recons_loss, kld_loss, Lcls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training EVAE"
      ],
      "metadata": {
        "id": "0wFHZC0odaAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "oGIht7gQcqm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check data we are using\n",
        "import os\n",
        "\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/healthcare_data/train_data2/class2'\n",
        "extension = '.png'\n",
        "\n",
        "num_files = len([f for f in os.listdir(directory) if f.endswith(extension)])\n",
        "\n",
        "print(f\"There are {num_files} {extension} files in {directory}\")\n"
      ],
      "metadata": {
        "id": "VeHpuRffbkwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms # need to adapt image format\n",
        "\n",
        "\n",
        "# Access train data\n",
        "train_dir = './train_data2' # CHECK PATH.\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "train_data = datasets.ImageFolder(train_dir, transform=transform)"
      ],
      "metadata": {
        "id": "RWtgOVgm-ovV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "siZyCYhz5v08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "L0Clzgek_jyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# Training loop\n",
        "\n",
        "losses = []\n",
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, y, mu, log_var = model(data)\n",
        "        target_onehot = F.one_hot(target, num_classes=4).float() \n",
        "        mse, kld, Lcls = model.loss_function(recon_batch, data, y, target_onehot, mu, log_var)\n",
        "        loss = mse + kld + Lcls\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "    losses.append(train_loss)\n"
      ],
      "metadata": {
        "id": "OV192UynYuQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = EVAE(latent_dim=256, num_classes=4).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00003) # lr can be adjusted\n",
        "epochs = 20 # epochs can be adjusted\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(model, optimizer, train_loader, device)"
      ],
      "metadata": {
        "id": "w6Sz5yncY01h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVAE Evaluation\n"
      ],
      "metadata": {
        "id": "caWdRypaWT75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access eval data\n",
        "test_dir = './test_data2' # CHECK PATH.\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "test_data = datasets.ImageFolder(test_dir, transform=transform)"
      ],
      "metadata": {
        "id": "oTXfyEP95Y7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "tkbDXFCB5n1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "def get_results(model, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    \n",
        "    y_true_int = []\n",
        "    y_pred_int = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(loader):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            _, y_hat, _, _ = model(data)\n",
        "            y_hat = torch.softmax(y_hat, dim=1)\n",
        "            y_true.extend(target.tolist())\n",
        "            y_pred.extend(y_hat.tolist())\n",
        "\n",
        "    y_true = F.one_hot(torch.tensor(y_true)).numpy()\n",
        "    y_pred = np.array(y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
        "    acc = accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "\n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "j45xRw4hGAxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = get_results(model, test_loader)"
      ],
      "metadata": {
        "id": "JinjzVBl5QYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference on Test Set"
      ],
      "metadata": {
        "id": "Gojo6fgTNYYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert format of get_results output\n",
        "y_true_int = []\n",
        "\n",
        "for ele in y_true:\n",
        "    class_label = ele.tolist().index(max(ele.tolist()))\n",
        "    y_true_int.append(class_label)"
      ],
      "metadata": {
        "id": "dl3JGi3yHkkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_int = []\n",
        "\n",
        "for ele in y_pred:\n",
        "    class_label = ele.tolist().index(max(ele.tolist()))\n",
        "    y_pred_int.append(class_label)"
      ],
      "metadata": {
        "id": "rC8ey82iIXxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to calculate multiclass AUC\n",
        "def multiclass_metrics(test, pred, average=\"macro\"):\n",
        "    \n",
        "    # Create set of unique classes\n",
        "    unique = set(test)\n",
        "    auc_dict = {}\n",
        "    acc_dict = {}\n",
        "    \n",
        "    # Loop through each class\n",
        "    for class_i in unique:\n",
        "        \n",
        "        # Create list of classes other than class_i\n",
        "        other_class = [x for x in unique if x != class_i]\n",
        "\n",
        "        # Get test / prediction values for each class\n",
        "        new_test = [0 if x in other_class else 1 for x in test]\n",
        "        new_pred = [0 if x in other_class else 1 for x in pred]\n",
        "        \n",
        "        #print(accuracy_score(new_test, new_pred))\n",
        "        accuracy = accuracy_score(new_test, new_pred)\n",
        "        acc_dict[class_i] = accuracy\n",
        "\n",
        "        # Calculate AUC, add to dictionary\n",
        "        auc = roc_auc_score(new_test, new_pred, average = average)\n",
        "        auc_dict[class_i] = auc\n",
        "        \n",
        "    return acc_dict, auc_dict"
      ],
      "metadata": {
        "id": "4PH2qBdYNVwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_acc, multi_auc = multiclass_metrics(y_true_int, y_pred_int, average=\"macro\")\n",
        "\n",
        "print('Multiclass AUC scores:')\n",
        "print(multi_auc)\n",
        "\n",
        "print('Multiclass accuracy scores:')\n",
        "print(multi_acc)"
      ],
      "metadata": {
        "id": "YateW_8vIUwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "overall_accuracy = accuracy_score(y_true_int, y_pred_int)\n",
        "overall_precision = precision_score(y_true_int, y_pred_int, average=\"macro\")\n",
        "overall_recall = recall_score(y_true_int, y_pred_int, average=\"macro\")\n",
        "overall_f1 = f1_score(y_true_int, y_pred_int, average=\"macro\")\n",
        "\n",
        "print(\"Overall Accuracy: \", overall_accuracy)\n",
        "print(\"Overall Precision: \", overall_precision)\n",
        "print(\"Overall Recall: \", overall_recall)\n",
        "print(\"Overall F1: \", overall_f1)"
      ],
      "metadata": {
        "id": "VymGODJGJm2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5AzvC1BKWVvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.2 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1da3383a1b58fe481baf23ca14731c20d0a972ba0c6221953a6c3e65df3165e3"
      }
    },
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}